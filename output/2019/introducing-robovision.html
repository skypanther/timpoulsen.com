
<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="../theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="../theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="../theme/css/main.css">
  <link rel="stylesheet" type="text/css" href="../theme/font-awesome/css/fontawesome.css">


    <link href="https://www.timpoulsen.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Tim Poulsen Atom">


  <link rel="apple-touch-icon" sizes="57x57" href="/images/favicons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/images/favicons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/images/favicons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/favicons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/images/favicons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/images/favicons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/images/favicons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/images/favicons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/images/favicons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/images/favicons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicons/favicon-16x16.png">
  <link rel="manifest" href="/images/favicons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/images/favicons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="index, follow" />

    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#143742">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#143742">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<meta name="author" content="Tim Poulsen" />
<meta name="description" content="The FIRST robotics competition (FRC) challenges high school students to design and build a robot capable of performing multiple challenging tasks. These annual challenges typically involve computer vision components, such as identifying and using reflective markers to locate targets. High school computer science curriculum rarely covers software engineering topics, let …" />
<meta name="keywords" content="python, opencv, robotics">
<meta property="og:site_name" content="Tim Poulsen"/>
<meta property="og:title" content="Introducing Robovision"/>
<meta property="og:description" content="The FIRST robotics competition (FRC) challenges high school students to design and build a robot capable of performing multiple challenging tasks. These annual challenges typically involve computer vision components, such as identifying and using reflective markers to locate targets. High school computer science curriculum rarely covers software engineering topics, let …"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="../2019/introducing-robovision.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-03-10 00:00:00-05:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="../author/tim-poulsen.html">
<meta property="article:section" content="OpenCV"/>
<meta property="article:tag" content="python"/>
<meta property="article:tag" content="opencv"/>
<meta property="article:tag" content="robotics"/>
<meta property="og:image" content="/images/tim_poulsen.jpg">

  <title>Tim Poulsen &ndash; Introducing Robovision</title>


    <link href="/theme/css/main.css" rel="stylesheet">

</head>
<body>
  <aside class="leftbar" style="background-color: #030E36;">
    <div class="leftbar" style="background-color: #030E36;">
      <a href="..">
        <img src="/images/tim_poulsen.jpg" alt="Tim Poulsen" title="Tim Poulsen">
      </a>
      <h1><a href="..">Tim Poulsen</a></h1>

<p class="subtitle">Explorations of software and hardware</p>
      <ul class="social">
        <li><a class="sc-twitter" href="https://twitter.com/skypanther" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-github" href="https://github.com/skypanther" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-linkedin" href="https://www.linkedin.com/in/timpoulsen" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        <li><a class="sc-keybase" href="https://keybase.io/skypanther" target="_blank"><i class="fa fa-keybase"></i></a></li>
        <li><a class="sc-rss" href="feeds/all.atom.xml" target="_blank"><i class="fa fa-rss"></i></a></li>
      </ul>

      <nav>
        <ul class="list">
          <li><a href="../pages/about.html#about">About</a></li>

          <li><a href="/categories.html" target="_blank">Topics</a></li>
          <li><a href="http://skypanther.com" target="_blank">Skypanther Studios</a></li>
        </ul>
      </nav>

      <p class="subhead">Tags:</p>
      <ul class="tagcloud">
          <li class="tag-1">
              <a href="../tag/python.html">
              python
              </a>
          </li>
          <li class="tag-1">
              <a href="../tag/opencv.html">
              opencv
              </a>
          </li>
          <li class="tag-2">
              <a href="../tag/raspberry-pi.html">
              raspberry pi
              </a>
          </li>
          <li class="tag-2">
              <a href="../tag/making.html">
              making
              </a>
          </li>
          <li class="tag-3">
              <a href="../tag/robotics.html">
              robotics
              </a>
          </li>
          <li class="tag-4">
              <a href="../tag/htmlcss.html">
              html/css
              </a>
          </li>
          <li class="tag-4">
              <a href="../tag/webdev.html">
              webdev
              </a>
          </li>
          <li class="tag-4">
              <a href="../tag/arduino.html">
              arduino
              </a>
          </li>
          <li class="tag-4">
              <a href="../tag/xmas.html">
              xmas
              </a>
          </li>
          <li class="tag-4">
              <a href="../tag/ios.html">
              iOS
              </a>
          </li>
          <li class="tag-4">
              <a href="../tag/swift.html">
              Swift
              </a>
          </li>
          <li class="tag-4">
              <a href="../tag/anaconda.html">
              anaconda
              </a>
          </li>
      </ul>

    </div>


  </aside>
  <main>

    <nav>
      <a href="..">    Home
</a>

      <a href="/categories.html">Topics</a>
      <a href="/pages/about.html">About</a>
      <a href="/tags.html">Tags</a>

      <a href="https://www.timpoulsen.com/feeds/all.atom.xml">    Atom
</a>

    </nav>

<article class="single">
  <header>
    <h1 id="introducing-robovision">Introducing Robovision</h1>
    <p>
          Posted on Sun 10 March 2019 in <a href="../category/opencv.html">OpenCV</a>


    </p>
  </header>


  <div>
    <p>The FIRST robotics competition (FRC) challenges high school students to design and build a robot capable of performing multiple challenging tasks. These annual challenges typically involve computer vision components, such as identifying and using reflective markers to locate targets. High school computer science curriculum rarely covers software engineering topics, let alone advanced topics like computer vision.</p>
<p>To help FRC teams, I have written the robovision python library. This library includes functions useful for the types of vision tasks typically involved in an FRC competition. The goal of this library is to reduce and hide some of the complexity involved with target identification, measuring, field orienteering, etc.</p>
<p>Robovision is open source, licenced under the permissive MIT license, and free for all FRC teams to use. You can install it from <a href="https://pypi.org/project/robovision/" target="_blank">PyPI</a> or directly from the <a href="https://github.com/skypanther/robovision" target="_blank">GitHub repo</a>.</p>
<p>Some of the functions included in robovision are:</p>
<ul>
<li>Multi-threaded image acquisition from a web cam, IP cam (i.e. Axis cam), Raspberry Pi camera, or Jetson onboard gstreamer camera</li>
<li>Lens distortion removal based on the camera calibrations created with the provided autocalibrate.py script</li>
<li>Retroreflective target identification, contour finding, and geometry finding functions</li>
<li>Image resizing, equalization, brightness and contrast adjustments, and more</li>
<li>A preprocessor class, which enables you to set up a pipeline of functions that will be applied in series to an image.</li>
<li>Overlay arrows, text, borders, or crosshairs on images</li>
<li>Rolling (moving) average calculations</li>
</ul>
<p>Robovision complements the <a href="https://robotpy.readthedocs.io/en/stable/" target="_blank">RobotPy library</a>. It does not duplicate functionality, nor is it meant to replace that excellent project. Team 1518 uses both robovision and the cscore and networktables components of RobotPy.</p>
<h2>Installation</h2>
<p>Requirements:</p>
<ul>
<li>Python 3.5+ (2.x is not supported)</li>
<li>OpenCV 3.4+ (4.x will probably work, but is untested)</li>
<li>Numpy</li>
</ul>
<p>Robovision is meant to run on a coprocessor (e.g. a Jetson or Raspberry Pi) and hasn't been tested on the RoboRio itself. While it probably works on a Windows computer, it was developed and is tested only on Mac OS and Linux systems.</p>
<p>Installation details are covered in the wiki's <a href="https://github.com/skypanther/robovision/wiki/Installation-and-System-Setup" target="_blank">Installation and System Setup</a> page.</p>
<h2>Example</h2>
<p>Here's a sample of how you might use robovision to calculate the distance in inches to a 12" piece of retro-reflective tape held horizontally and face-on to an IP camera:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">robovision</span> <span class="kn">as</span> <span class="nn">rv</span>

<span class="n">source</span> <span class="o">=</span> <span class="s2">&quot;http://10.15.18.100/mjpg/video.mjpg&quot;</span>
<span class="n">fl</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Calculated apparent focal length of your camera</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">namedWindow</span><span class="p">(</span><span class="s1">&#39;CapturedImage&#39;</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WINDOW_NORMAL</span><span class="p">)</span>

<span class="c1"># connect to our streaming video source and start the capture thread</span>
<span class="n">vs</span> <span class="o">=</span> <span class="n">rv</span><span class="o">.</span><span class="n">get_video_stream</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
<span class="n">vs</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="c1"># instantiate a robovision Target object which does all the work of finding</span>
<span class="c1"># and isolating the retro-reflective tape</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">rv</span><span class="o">.</span><span class="n">Target</span><span class="p">()</span>
<span class="n">target</span><span class="o">.</span><span class="n">set_color_range</span><span class="p">(</span><span class="n">lower</span><span class="o">=</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">upper</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">))</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="n">vs</span><span class="o">.</span><span class="n">read_frame</span><span class="p">()</span>
    <span class="c1"># get a list of contours around objects within the color range set</span>
    <span class="c1"># above; these will be the retro-reflective tape assuming you&#39;re using</span>
    <span class="c1"># the standard AndyMark green LED light source</span>
    <span class="n">contours</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">get_contours</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">contours</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># draw a red border around each of the contours that were found</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">drawContours</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">contours</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
        <span class="c1"># assuming you&#39;re holding the tape horizontally, you need only</span>
        <span class="c1"># the width (in pixels) of the detected object</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">get_rectangle</span><span class="p">(</span><span class="n">for_contour</span><span class="o">=</span><span class="n">contours</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Distance from formula: D’ = (W x F) / P</span>
        <span class="n">d</span> <span class="o">=</span> <span class="mi">12</span> <span class="o">*</span> <span class="n">fl</span> <span class="o">/</span> <span class="n">w</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Distance to tape: {} inches&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;CapturedImage&#39;</span><span class="p">,</span> <span class="n">frame</span><span class="p">)</span>
    <span class="c1"># wait for Esc or q key and then exit</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span>
    <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="mi">27</span> <span class="ow">or</span> <span class="n">key</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;q&quot;</span><span class="p">):</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
        <span class="n">vs</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
        <span class="k">break</span>
</pre></div>
</td></tr></table>

<h3>Examples and documentation</h3>
<p>I include a selection of example scripts in the <a href="https://github.com/skypanther/robovision/tree/master/extras" target="_blank">extras folder</a> in the GitHub repo. While not really production ready, these show how to perform selected vision tasks that might be helpful for an FRC challenge. There's also a couple of scripts to help you do lens calibration (used to remove lens distortions, also called field flattening).</p>
<p>Be sure to check out the <a href="https://github.com/skypanther/robovision/wiki" target="_blank">project's wiki</a> for documentation on the library's classes and functions. You'll need the numpy and OpenCV python packages to use robovision. Some of the example scripts use additional libraries. </p>
<p>FRC Team 1518, Raider Robotics used robovision successfully in its 2019 Deep Space Challenge bot. So, another good source of examples (as well as some "incomplete thoughts") is the <a href="https://github.com/Raider-Robotics-Team-1518/Jetson" target="_blank">team's GitHub repository</a>.</p>
<h3>Future</h3>
<p>Looking ahead, the library needs even more simplification and abstraction to make it easy for FRC teams to use. Additional documentation and examples are also needed. I have not extensively tested or optimized the library for the Raspberry Pi (we're using a Jetson TX2, which has plenty of horsepower for our vision tasks). I very much welcome pull requests and contributions to the project.</p>
<p>#omgrobots!</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="../tag/python.html">python</a>
      <a href="../tag/opencv.html">opencv</a>
      <a href="../tag/robotics.html">robotics</a>
    </p>
  </div>




</article>

    <footer>
<p>
  &copy; Tim Poulsen 2020 - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
         src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>





<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Tim Poulsen ",
  "url" : "..",
  "image": "/images/tim_poulsen.jpg",
  "description": "Tim Poulsen's blog of software, hardware, and life"
}
</script>
</body>
</html>